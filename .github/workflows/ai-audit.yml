name: AI Audit Guardrails

on:
  pull_request:
    branches: [ main ]
  push:
    branches: [ main ]
  schedule:
    - cron: "0 2 * * *"  # Daily at 2 AM UTC

permissions:
  contents: read

jobs:
  ai-audit:
    runs-on: ubuntu-22.04
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Warm-up AI caches
        env:
          HF_HOME: ~/.cache/huggingface
          HF_HUB_CACHE: ~/.cache/huggingface/hub
          AURA_EMBED_CACHE_DIR: ~/.cache/aura/embeddings
        run: |
          mkdir -p "$HF_HUB_CACHE" "$AURA_EMBED_CACHE_DIR"
          node scripts/audit/ai/warmup.js --embeddings 25 --llm 25 --dataset scripts/audit/ai/router-bench.dataset.json

      - name: Run AI embeddings health check
        run: node scripts/audit/ai/embeddings-health.js

      - name: Run AI router benchmark
        run: node scripts/audit/ai/router-bench.js --dataset scripts/audit/ai/router-bench.dataset.json

      - name: Run full AI audit
        run: node scripts/audit/ai/audit-orchestrator.js

      - name: Enforce AI SLO thresholds
        run: |
          set -e
          echo "üîç Enforcing AI SLO thresholds..."
          
          # Extract metrics from reports
          EMB_P50=$(jq -r '.performance.p50_latency_ms // 999' reports/audit/AI/embeddings-cache-report.json)
          ROUTER_ACC=$(jq -r '.accuracy // 0' reports/audit/AI/router-bench.json)
          ROUTER_BYP=$(jq -r '.bypass_detection_rate // 0' reports/audit/AI/router-bench.json)
          
          echo "üìä Metrics: Embeddings P50=${EMB_P50}ms, Router Accuracy=${ROUTER_ACC}, Bypass=${ROUTER_BYP}"
          
          # SLO enforcement using awk for floating point comparison
          [ "$(printf "%.0f" "$EMB_P50")" -le 30 ] || (echo "‚ùå SLO VIOLATION: Embeddings P50 ${EMB_P50}ms > 30ms" && exit 1)
          awk "BEGIN { exit !(${ROUTER_ACC} >= 0.75) }" || (echo "‚ùå SLO VIOLATION: Router accuracy ${ROUTER_ACC} < 0.75" && exit 1)
          awk "BEGIN { exit !(${ROUTER_BYP} >= 0.65) }" || (echo "‚ùå SLO VIOLATION: Bypass detection ${ROUTER_BYP} < 0.65" && exit 1)
          
          echo "‚úÖ All AI SLO thresholds met"

      - name: Validate models manifest compliance
        run: |
          echo "üîç Validating models manifest compliance..."
          
          # Check if models.manifest.json exists
          if [ ! -f "config/models.manifest.json" ]; then
            echo "‚ùå Missing config/models.manifest.json"
            exit 1
          fi
          
          # Validate JSON structure
          jq empty config/models.manifest.json || (echo "‚ùå Invalid JSON in models.manifest.json" && exit 1)
          
          # Check required fields and SHA-256 hashes
          jq -e '.models.embeddings.slo.p50_ms_max' config/models.manifest.json >/dev/null || (echo "‚ùå Missing embeddings SLO" && exit 1)
          jq -e '.models.llm.slo.p50_ms_max' config/models.manifest.json >/dev/null || (echo "‚ùå Missing LLM SLO" && exit 1)
          jq -e '.models.embeddings.sha256' config/models.manifest.json >/dev/null || (echo "‚ùå Missing embeddings SHA-256" && exit 1)
          jq -e '.models.llm.sha256' config/models.manifest.json >/dev/null || (echo "‚ùå Missing LLM SHA-256" && exit 1)
          
          # Validate SHA-256 format (64 hex chars)
          EMB_HASH=$(jq -r '.models.embeddings.sha256' config/models.manifest.json)
          LLM_HASH=$(jq -r '.models.llm.sha256' config/models.manifest.json)
          [[ "$EMB_HASH" =~ ^[a-f0-9]{64}$ ]] || (echo "‚ùå Invalid embeddings SHA-256 format" && exit 1)
          [[ "$LLM_HASH" =~ ^[a-f0-9]{64}$ ]] || (echo "‚ùå Invalid LLM SHA-256 format" && exit 1)
          
          echo "‚úÖ Models manifest compliance validated with SHA-256 integrity"

      - name: Upload AI audit artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ai-audit-reports-${{ github.run_number }}
          path: |
            reports/audit/AI/**
            config/models.manifest.json
            scripts/audit/ai/router-bench.dataset.json
          retention-days: 30

      - name: Comment PR with AI metrics
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            try {
              const embReport = JSON.parse(fs.readFileSync('reports/audit/AI/embeddings-cache-report.json', 'utf8'));
              const routerReport = JSON.parse(fs.readFileSync('reports/audit/AI/router-bench.json', 'utf8'));
              
              const metrics = `## ü§ñ AI Performance Metrics
              
              ### ‚ö° Embeddings
              - **P50/P95/P99**: ${embReport.performance.p50_latency_ms}/${embReport.performance.p95_latency_ms}/${embReport.performance.p99_latency_ms}ms
              - **Cache Hit Ratio**: ${(embReport.cache.hit_ratio * 100).toFixed(1)}%
              - **Error Rate**: ${(embReport.performance.error_rate * 100).toFixed(2)}%
              
              ### üéØ Router
              - **Accuracy**: ${(routerReport.accuracy * 100).toFixed(1)}%
              - **Bypass Detection**: ${(routerReport.bypass_detection_rate * 100).toFixed(1)}%
              - **P50/P95/P99**: ${routerReport.latency.p50_ms}/${routerReport.latency.p95_ms}/${routerReport.latency.p99_ms}ms
              - **Error Rate**: ${(routerReport.error_rate * 100).toFixed(2)}%
              
              ### üíª System
              - **OS**: ${embReport.system.os}
              - **CPU**: ${embReport.system.cpu}
              - **RAM**: ${embReport.system.ram_gb}GB
              - **Node**: ${embReport.system.node}
              
              üìÑ Full reports available in CI artifacts.`;
              
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: metrics
              });
            } catch (error) {
              console.log('Could not generate AI metrics comment:', error.message);
            }