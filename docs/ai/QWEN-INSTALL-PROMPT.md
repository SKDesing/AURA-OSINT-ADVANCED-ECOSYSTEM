# üöÄ AURA ‚Äì PROMPT D'INSTALLATION & INT√âGRATION PROFESSIONNELLE QWEN (LOCAL ‚Üí CLOUD)

Ce document est le SCRIPT D'EX√âCUTION OFFICIEL pour les √©quipes (Backend, IA, DevOps, S√©curit√©, Data) afin d'installer, v√©rifier et int√©grer Qwen **en local souverain** (CPU) puis pr√©parer l'extension **GPU / Cloud surpuissant** + future version fine‚Äëtun√©e maison.

> NE PAS SAUTER D'√âTAPE ‚Äì TOUTE D√âVIATION = PR REFUS√âE  
> OBJECTIF PHASE IMM√âDIATE : Qwen2 1.5B Instruct quantifi√© (GGUF Q4_K_M) via llama.cpp + Gateway existante (placeholder)  
> PHASES SUIVANTES : Qwen 7B / 14B / 32B GPU (vLLM), Fine-tune LoRA maison, Cloud scaling

---

## 0. PRINCIPES (RAPPEL)

| Principe | Application Qwen |
|----------|------------------|
| Souverainet√© | T√©l√©chargement direct Hugging Face, hash SHA256, offline apr√®s bootstrap |
| Reproductibilit√© | Pin commit HF + stocker `MODEL_COMMIT` + `sha256` |
| Z√©ro fuite | `HF_HUB_OFFLINE=1` apr√®s download, ex√©cution 127.0.0.1 uniquement |
| S√©curit√© | V√©rif hash avant lancement, pas de logs prompts bruts si `AI_LOG_PROMPTS=false` |
| Portabilit√© | M√™me contrat API local ‚Üî cloud (/ai/local/qwen/generate & /ai/cloud/qwen/generate) |
| Mesure | Bench p50/p95/p99, tokens/sec, saturation m√©moire |
| Observabilit√© | Metrics Prometheus (ajout phase: 1.1) |

---

## 1. MATRICE D'ENVIRONNEMENTS

| Environnement | Objectif | Runtime | Quantisation / Format | Cible RAM / VRAM | Status |
|---------------|----------|---------|-----------------------|------------------|--------|
| Laptop CPU (Phase 1) | Prototypage prompts & capture dataset | llama.cpp server | GGUF Q4_K_M | ~4‚Äì5 Go | Activer maintenant |
| Workstation GPU (Phase 2) | Tests latence + long context | PyTorch + vLLM | BF16 / FP16 | 16‚Äì24 Go VRAM | Pr√©parer |
| Cloud GPU (Phase 4) | Haute capacit√© + multi-concurrence | vLLM (container) | FP16 + Paged KV | 40‚Äì80 Go VRAM | Plus tard |
| Fine-tune (Phase 5) | Adaptation maison | PEFT (LoRA) | bfloat16 + LoRA | 24+ Go VRAM | Plus tard |

---

## 2. VARIABLES D'ENVIRONNEMENT (AJOUTER .env)

```
AI_QWEN_MODEL_FILE=ai/local-llm/models/qwen2-1_5b-instruct-q4_k_m.gguf
AI_QWEN_PORT=8090
AI_QWEN_CONTEXT=3072
AI_MAX_INPUT_CHARS=6000
AI_BLOCKED_PATTERNS=ignore previous;system override;exfiltrate;delete all data
AI_PII_REDACTION=true
AI_LOG_PROMPTS=false
AI_DATASET_CAPTURE=true
AI_DATASET_DIR=ai/dataset/captured
AI_GATEWAY_PORT=4010
HF_HUB_OFFLINE=1
```

---

## 3. INSTALLATION LOCAL (CPU) ‚Äì PHASE IMM√âDIATE

### 3.1 Pr√©-requis syst√®me
```bash
node --version          # >=18 LTS
gcc --version           # AVX2 support recommand√©
grep avx2 /proc/cpuinfo | head -1 || echo "‚ö†Ô∏è AVX2 absent (performances r√©duites)"
python3 --version       # >=3.9 (future phase)
cmake --version         # >=3.24 (pour build optionnel)
```

### 3.2 T√©l√©chargement mod√®le (script d√©j√† fourni)
```bash
bash ai/local-llm/scripts/download-qwen2-1_5b.sh
cat ai/local-llm/models/qwen2-1_5b-instruct-q4_k_m.gguf.sha256
```

### 3.3 V√©rification int√©grit√©
```bash
sha256sum -c ai/local-llm/models/qwen2-1_5b-instruct-q4_k_m.gguf.sha256
# Doit retourner OK
```

### 3.4 Build & Run llama.cpp (d√©j√† script√©)
```bash
bash ai/local-llm/scripts/run-llm-qwen.sh &
sleep 4
curl -s -X POST http://127.0.0.1:$AI_QWEN_PORT/completion \
 -H "Content-Type: application/json" \
 -d '{"prompt":"‰Ω†Â•ΩÔºåÁÆÄËø∞AURAÁ≥ªÁªü„ÄÇ", "temperature":0.3, "n_predict":128}' | jq
```

### 3.5 Hardening minimal
- V√©rifier port bind: `ss -ltnp | grep 8090 | grep 127.0.0.1`
- Aucune connection externe: `sudo lsof -i | grep llama || echo "‚úÖ Offline"`

---

## 4. CHECKLIST "DONE" (PHASE 1 QWEN LOCAL)

| Code | Item | Attendu | Statut |
|------|------|---------|--------|
| QW-01 | Mod√®le t√©l√©charg√© | .gguf + .sha256 | ‚è≥ |
| QW-02 | Hash v√©rifi√© | sha256 OK | ‚è≥ |
| QW-03 | Serveur llama.cpp | port 8090 up (127.0.0.1) | ‚è≥ |
| QW-04 | Prompt test zh | r√©ponse non vide | ‚è≥ |
| QW-05 | Gateway placeholder | still operational | ‚è≥ |
| QW-06 | Int√©gration future planifi√©e | doc QWEN-INSTALL-PROMPT.md | ‚úÖ |
| QW-07 | Pas de fuite net | lsof / netstat OK | ‚è≥ |
| QW-08 | Dataset capture | fichier du jour cr√©√© | ‚è≥ |
| QW-09 | Guardrails input | patterns bloqu√©s test√©s | ‚è≥ |
| QW-10 | Bench initial | p95 < 2.5s | ‚è≥ |

---

## 5. COMMANDES R√âSUM√âES (COPIER-COLLER)

```bash
# 1. Download + verify
bash ai/local-llm/scripts/download-qwen2-1_5b.sh
sha256sum -c ai/local-llm/models/qwen2-1_5b-instruct-q4_k_m.gguf.sha256

# 2. Run server
bash ai/local-llm/scripts/run-llm-qwen.sh &

# 3. Test prompt
curl -s -X POST http://127.0.0.1:$AI_QWEN_PORT/completion \
 -H "Content-Type: application/json" \
 -d '{"prompt":"‰Ω†Â•ΩÔºåÁÆÄËø∞AURAÁ≥ªÁªü„ÄÇ", "n_predict":128}' | jq '.content[0].text'

# 4. V√©rifier dataset capture (apr√®s gateway int√©gration r√©elle)
ls ai/dataset/captured
```

---

## 6. PROCHAINES ACTIONS (APR√àS "GREEN")

| √âtape | Action | Issue Tag |
|-------|--------|-----------|
| 1 | Remplacer placeholder QwenService | feat(ai) |
| 2 | Ajouter m√©triques prom-client (tokens, latence) | obs(ai) |
| 3 | Int√©grer segmentation zh (nodejieba) si besoins classification | feat(ai-nlp) |
| 4 | Introduire test adversarial guardrails | sec(ai) |
| 5 | Pr√©parer spec embeddings (bge-small-zh) | feat(rag) |

---

Fin ‚Äì Ce document est l'UNIQUE source de v√©rit√© pour l'installation Qwen Phase 1.  
Ex√©cuter, cocher, puis ouvrir PR "feat(ai): integrate qwen local phase1".