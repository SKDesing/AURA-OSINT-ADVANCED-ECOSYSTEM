#!/bin/bash
# Script pour dÃ©marrer Qwen avec Ollama

echo "ğŸš€ DÃ©marrage Qwen pour AURA AI Orchestrator"
echo "==========================================="

# VÃ©rifier si Ollama est installÃ©
if ! command -v ollama &> /dev/null; then
    echo "âŒ Ollama n'est pas installÃ©"
    echo "ğŸ“¥ Installation d'Ollama..."
    curl -fsSL https://ollama.ai/install.sh | sh
fi

# DÃ©marrer le service Ollama
echo "ğŸ”„ DÃ©marrage du service Ollama..."
ollama serve &
sleep 5

# VÃ©rifier si le modÃ¨le Qwen est disponible
if ! ollama list | grep -q "qwen2.5"; then
    echo "ğŸ“¥ TÃ©lÃ©chargement du modÃ¨le Qwen2.5..."
    ollama pull qwen2.5:latest
fi

echo "âœ… Qwen est prÃªt sur http://localhost:11434"
echo "ğŸ§  ModÃ¨le: qwen2.5:latest"
echo ""
echo "ğŸ”— Test de connexion:"
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen2.5:latest",
    "prompt": "Hello, I am AURA AI Orchestrator",
    "stream": false
  }' | jq .

echo ""
echo "ğŸš€ Vous pouvez maintenant dÃ©marrer le backend:"
echo "   npm run start:dev"